{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f33269c6",
   "metadata": {},
   "source": [
    "# Отбор признаков "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e541b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2342f7e0",
   "metadata": {},
   "source": [
    "При таком разнообразии способов, позволяющих сгенерировать новые\n",
    "признаки, у вас, возможно, возникнет искушение увеличить размерность \n",
    "данных, превысив количество исходных признаков. Однако добавление \n",
    "новых признаков делает модели более сложными и поэтому увеличивает \n",
    "вероятность переобучения. Добавляя новые признаки или работая с\n",
    "высокоразмерными наборами данных, неплохо бы уменьшить количество \n",
    "признаков и оставить только наиболее полезные из них.\n",
    "Это позволит получить более простые модели с лучшей обобщающей способностью. \n",
    "\n",
    "**Однако как узнать, насколько полезен каждый признак?** \n",
    "\n",
    "Существуют три основные стратегии: **одномерные статистики** (univariate statistics), **отбор\n",
    "на основе модели** (model-based selection) и **итеративный отбор** (iterative\n",
    "selection).\n",
    "*Все эти методы относятся методам машинного обучения с учителем, то есть для подгонки \n",
    "модели им требуется зависимая переменная. Это означает, что нам нужно \n",
    "разбить данные на обучающий и тестовый наборы и осуществить отбор \n",
    "признаков лишь на обучающей выборке*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef51b6c6",
   "metadata": {},
   "source": [
    "### Одномерные статистики"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a29b4c4",
   "metadata": {},
   "source": [
    "С помощью одномерных статистик мы определяем наличие \n",
    "статистически значимой взаимосвязи между каждым признаком и\n",
    "зависимой переменной. Затем отбираем признаки, сильнее всего \n",
    "связанные с зависимой переменной (имеющие уровень значимости, не \n",
    "превышающий заданного порогового значения). В случае классификации\n",
    "эта процедура известна как **дисперсионный анализ (ANOVA)**. Ключевым \n",
    "свойством этих тестов является то, что они являются одномерными, то \n",
    "есть они рассматривают каждую характеристику по отдельности. \n",
    "Следовательно признак будет исключен, если он становится\n",
    "информативным лишь в сочетании с другим признаком. Как правило, \n",
    "одномерные тесты очень быстро вычисляются и не требуют построения \n",
    "модели. С другой стороны, они являются полностью независимыми от \n",
    "модели, которой вы, возможно, захотите применить после отбора\n",
    "признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5bfa1d",
   "metadata": {},
   "source": [
    "Чтобы осуществить одномерный отбор признаков в scikit-learn, вам \n",
    "нужно выбрать тест, обычно либо **f_classif** (по умолчанию) для \n",
    "классификации или **f_regression** для регрессии, а также метод \n",
    "исключения признаков, основанный на *р-значениях*, вычисленных в ходе\n",
    "теста. Все методы исключения параметров используют пороговое \n",
    "значение, чтобы исключить все признаки со слишком высоким *р-значением* (высокое p-значение указывает на то, что признак вряд ли \n",
    "связан с зависимой переменной). Методы отличаются способами\n",
    "вычисления этого порогового значения, самым простым из которых \n",
    "являются **SelectKB**, выбирающий фиксированное число k признаков, и \n",
    "**SelectPercentile**, выбирающий фиксированный процент признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5364a3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6981dbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "форма массива X_train: (284, 80)\n",
      "форма массива X_train_selected: (284, 40)\n"
     ]
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "\n",
    "# задаем определенное стартовое значение для воспроизводимости результата\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# добавляем к данным шумовые признаки\n",
    "noise = rng.normal(size=(len(cancer.data), 50))\n",
    "\n",
    "# первые 30 признаков являются исходными, остальные 50 являются шумовыми\n",
    "X_w_noise = np.hstack([cancer.data, noise])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_w_noise, cancer.target, random_state=0, test_size=.5)\n",
    "\n",
    "# используем f_classif (по умолчанию)\n",
    "# и SelectPercentile, чтобы выбрать 50% признаков\n",
    "select = SelectPercentile(score_func=f_classif, percentile=50)\n",
    "select.fit(X_train, y_train)\n",
    "\n",
    "# преобразовываем обучающий набор\n",
    "X_train_selected = select.transform(X_train)\n",
    " \n",
    "print(\"форма массива X_train: {}\".format(X_train.shape))\n",
    "print(\"форма массива X_train_selected: {}\".format(X_train_selected.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b1da5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True False  True False\n",
      "  True  True  True  True  True  True False False  True  True  True  True\n",
      "  True  True  True  True  True  True False False False  True False  True\n",
      " False False  True False False False False  True False False  True False\n",
      " False  True False  True False False False False False False  True False\n",
      "  True False False False False  True False  True False False False False\n",
      "  True  True False  True False False False False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Индекс примера')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = select.get_support()\n",
    "print(mask)\n",
    "# визуализируем булевы значения: черный – True, белый – False\n",
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
    "plt.xlabel(\"Индекс примера\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb2dbe1",
   "metadata": {},
   "source": [
    "Благодаря визуализации видно, что большинство отобранных \n",
    "признаков являются исходными характеристиками, а большинство \n",
    "шумовых признаков были удалены. Тем не менее восстановление \n",
    "исходных признаков далеко от идеала."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2050e37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dermi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильность со всеми признаками: 0.930\n",
      "Правильность только с отобранными признаками: 0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dermi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# преобразовываем тестовые данные\n",
    "X_test_selected = select.transform(X_test)\n",
    "lr = LogisticRegression(max_iter=1000);\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"Правильность со всеми признаками: {:.3f}\".format(lr.score(X_test, y_test)))\n",
    "lr.fit(X_train_selected, y_train)\n",
    "print(\"Правильность только с отобранными признаками: {:.3f}\".format(\n",
    "lr.score(X_test_selected, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e31911",
   "metadata": {},
   "source": [
    "Это был очень простой синтетический пример, результаты, \n",
    "получающиеся на реальных данных, как правило, получаются \n",
    "смешанными. Однако одномерный отбор признаков может быть очень \n",
    "полезен, если их количество является настолько большим, что \n",
    "невозможно построить модель, используя все эти характеристики, или \n",
    "же вы подозреваете, что многие характеристики совершенно \n",
    "неинформативны."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d0f75f",
   "metadata": {},
   "source": [
    "### Отбор признаков на основе модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceac1ecb",
   "metadata": {},
   "source": [
    "Отбор признаков на основе модели использует модель машинного \n",
    "обучения с учителем, чтобы вычислить важность каждого признака, и \n",
    "оставляет только самые важные из них. **Модель машинного обучения с \n",
    "учителем, которая используется для отбора признаков, не должна\n",
    "использоваться для построения итоговой модели.**\n",
    "\n",
    "------------\n",
    "Модель, применяющаяся для отбора признаков, требует вычисления \n",
    "определенного показателя важности для всех признаков, с тем чтобы\n",
    "характеристики можно было ранжировать по этой метрике. В деревьях\n",
    "решений и моделях на основе дерева решений такой показатель\n",
    "реализован с помощью атрибута **feature_importances_**, в котором \n",
    "записывается важность каждого признака. У линейных моделей есть\n",
    "коэффициенты, абсолютные значения которых также можно\n",
    "использовать для оценки важности признаков. \n",
    "\n",
    "Как мы знаем, **линейные модели с L1 регуляризацией** позволяют вычислить разреженные \n",
    "решения, которые используют лишь небольшое подмножество \n",
    "признаков. Поэтому процедуру L1 регуляризации можно рассматривать \n",
    "как один из способов отбора признаков, выполняемый самой моделью.\n",
    "Кроме того, эту процедуру можно использовать в качестве инструмента \n",
    "предварительной обработки, позволяющего отобрать признаки для \n",
    "другой модели. \n",
    "\n",
    "----------------\n",
    "*В отличие от одномерного отбора отбор на основе модели \n",
    "рассматривает все признаки сразу и поэтому может обнаружить\n",
    "взаимодействия (если модель способна выявить их).*\n",
    "\n",
    "Чтобы применить отбор на основе модели, мы должны воспользоваться модификатором **SelectFromModel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d80d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6238ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "select = SelectFromModel(random_forest, threshold='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef42618",
   "metadata": {},
   "source": [
    "Класс SelectFromModel отбирает все признаки, у которых показатель \n",
    "важности (заданный моделью машинного обучения с учителем) \n",
    "превышает установленное пороговое значение. Чтобы вычислить\n",
    "результат, сопоставимый с тем, который мы получили при\n",
    "однофакторном отборе признаков, мы использовали в качестве \n",
    "порогового значения медиану, поэтому будет отобрана половина \n",
    "признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c58796",
   "metadata": {},
   "outputs": [],
   "source": [
    "select.fit(X_train, y_train) # обучение\n",
    "\n",
    "X_train_selected = select.transform(X_train) # отбор \n",
    "\n",
    "print(\"форма обуч набора X: {}\".format(X_train.shape))\n",
    "print(\"форма обуч набора X c l1: {}\".format(X_train_selected.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee67d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = select.get_support()\n",
    "# визуализируем булевы значения -- черный – True, белый – False\n",
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
    "plt.xlabel(\"Индекс примера\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e1095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_l1 = select.transform(X_test)\n",
    "score = LogisticRegression().fit(X_train_selected, y_train).score(X_test_l1, y_test)\n",
    "print(\"Правильность на тестовом наборе: {:.3f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae9abdf",
   "metadata": {},
   "source": [
    "*Использовав более оптимальный отбор признаков, мы смогли \n",
    "немного улучшить прогноз*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e575498d",
   "metadata": {},
   "source": [
    "### Итеративный отбор признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c4a503",
   "metadata": {},
   "source": [
    "В одномерном отборе признаков мы не использовали модель, а в отборе \n",
    "признаков на основе модели мы построили одну модель, чтобы выбрать\n",
    "характеристики. В итеративном отборе признаков строится \n",
    "последовательность моделей с различным количеством признаков. \n",
    "Существует два основных метода.\n",
    "\n",
    "- Первый метод начинается шага, когда \n",
    "в модель включена лишь одна константа (входных признаков нет) и\n",
    "затем добавляет признак за признаком до тех пор, пока не будет \n",
    "достигнут критерий остановки. \n",
    "\n",
    "\n",
    "- Второй метод начинается с шага, когда \n",
    "все признаки включены в модель, и затем начинает удалять признак за \n",
    "признаком, пока не будет достигнут критерий остановки. \n",
    "\n",
    "*Поскольку строится последовательность модели, эти методы с вычислительной \n",
    "точки зрения являются гораздо более затратными в отличие от ранее \n",
    "обсуждавшихся методов*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68b6b60",
   "metadata": {},
   "source": [
    "Одним из таких методов является **метод \n",
    "рекурсивного исключения признаков**(recursive feature elimination, **RFE**), \n",
    "который начинается с включения всех признаков, строит модель и \n",
    "исключает наименее важный признак с точки зрения модели. Затем \n",
    "строится новая модель с использованием всех признаков, кроме \n",
    "исключенного, и так далее, пока не останется лишь заранее определенное \n",
    "количество признаков. Чтобы все получилось, модели, используемой для \n",
    "отбора признаков, необходима определенная метрика, измеряющая\n",
    "важность признаков, как было в случае с модельным отбором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e8e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc3380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "select = RFE(random_forest, n_features_to_select=40)\n",
    "\n",
    "select.fit(X_train, y_train)\n",
    "\n",
    "# визуализируем отобранные признаки:\n",
    "mask = select.get_support()\n",
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
    "plt.xlabel(\"Индекс примера\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d085e3",
   "metadata": {},
   "source": [
    "*Отбор признаков стал лучше по сравнению с одномерным отбором и \n",
    "отбором на основе модели, однако одного признака по-прежнему не \n",
    "хватает. Кроме того, выполнение этого программного кода занимает \n",
    "значительно больше времени в отличие от модельного отбора, поскольку \n",
    "модель случайного леса обучается 40 раз, по одной итерации для каждого \n",
    "отбрасываемого признака.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dbc3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe= select.transform(X_train)\n",
    "X_test_rfe= select.transform(X_test)\n",
    "score = LogisticRegression().fit(X_train_rfe, y_train).score(X_test_rfe, y_test)\n",
    "print(\"Правильность на тестовом наборе: {:.3f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df8d3e7",
   "metadata": {},
   "source": [
    "## Вместо вывода"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d55ec5",
   "metadata": {},
   "source": [
    "Если у вас нет уверенности в том, какие признаки использовать в \n",
    "качестве входных данных для вашего алгоритма машинного обучения, \n",
    "автоматический отбор признаков может быть весьма полезен. Кроме того, \n",
    "он отлично подходит для уменьшения количества необходимых \n",
    "признаков, например, чтобы увеличить скорость вычисления прогнозов \n",
    "или получить более интерпретируемые модели. В большинстве реальных \n",
    "примеров применение отбора признаков вряд ли обеспечит большой \n",
    "прирост производительности. Тем не менее, он по-прежнему является \n",
    "ценным инструментом в арсенале специалиста по анализу данных.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01af0f45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
